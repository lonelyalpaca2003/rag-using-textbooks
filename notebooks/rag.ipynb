{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings, StorageContext, Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pypdf\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents_with_metadata_included(data_path:str):\n",
    "    all_docs = []\n",
    "    for filename in os.listdir(data_path):\n",
    "        if not filename.endswith('.pdf'):\n",
    "            continue\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        reader = pypdf.PdfReader(file_path)\n",
    "\n",
    "        if \"lecture\" in filename.lower():\n",
    "            doc_type = \"lecture\"\n",
    "\n",
    "        if 'lecture' not in filename.lower():\n",
    "            doc_type = \"textbook\"\n",
    "\n",
    "        for page_num, page in enumerate(reader.pages):\n",
    "            text = page.extract_text()\n",
    "            doc = Document(text = text, \n",
    "                           metadata = {\n",
    "                               \"file_name\" : filename, \n",
    "                               \"page_num\" : page_num, \n",
    "                               \"doc_type\" : doc_type,\n",
    "                               \"course\" : \"Machine Learning\"\n",
    "                           })     \n",
    "            all_docs.append(doc)\n",
    "            \n",
    "\n",
    "    return all_docs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 173 0 (offset 0)\n",
      "Ignoring wrong pointing object 376 0 (offset 0)\n",
      "Ignoring wrong pointing object 393 0 (offset 0)\n",
      "Ignoring wrong pointing object 425 0 (offset 0)\n",
      "Ignoring wrong pointing object 427 0 (offset 0)\n",
      "Ignoring wrong pointing object 434 0 (offset 0)\n",
      "Ignoring wrong pointing object 652 0 (offset 0)\n",
      "Ignoring wrong pointing object 678 0 (offset 0)\n",
      "Ignoring wrong pointing object 781 0 (offset 0)\n",
      "Ignoring wrong pointing object 837 0 (offset 0)\n",
      "Ignoring wrong pointing object 840 0 (offset 0)\n",
      "Ignoring wrong pointing object 843 0 (offset 0)\n",
      "Ignoring wrong pointing object 854 0 (offset 0)\n",
      "Ignoring wrong pointing object 885 0 (offset 0)\n",
      "Ignoring wrong pointing object 929 0 (offset 0)\n",
      "Ignoring wrong pointing object 1050 0 (offset 0)\n",
      "Ignoring wrong pointing object 1092 0 (offset 0)\n",
      "Ignoring wrong pointing object 1125 0 (offset 0)\n",
      "Ignoring wrong pointing object 1138 0 (offset 0)\n",
      "Ignoring wrong pointing object 1140 0 (offset 0)\n",
      "Ignoring wrong pointing object 1149 0 (offset 0)\n",
      "Ignoring wrong pointing object 1157 0 (offset 0)\n",
      "Ignoring wrong pointing object 1161 0 (offset 0)\n",
      "Ignoring wrong pointing object 1163 0 (offset 0)\n",
      "Ignoring wrong pointing object 1173 0 (offset 0)\n",
      "Ignoring wrong pointing object 1200 0 (offset 0)\n",
      "Ignoring wrong pointing object 1202 0 (offset 0)\n",
      "Ignoring wrong pointing object 1276 0 (offset 0)\n",
      "Ignoring wrong pointing object 1280 0 (offset 0)\n",
      "Ignoring wrong pointing object 1290 0 (offset 0)\n",
      "Ignoring wrong pointing object 1425 0 (offset 0)\n",
      "Ignoring wrong pointing object 1452 0 (offset 0)\n",
      "Ignoring wrong pointing object 1512 0 (offset 0)\n",
      "Ignoring wrong pointing object 1551 0 (offset 0)\n",
      "Ignoring wrong pointing object 1578 0 (offset 0)\n",
      "Ignoring wrong pointing object 1588 0 (offset 0)\n",
      "Ignoring wrong pointing object 1645 0 (offset 0)\n",
      "Ignoring wrong pointing object 1650 0 (offset 0)\n",
      "Ignoring wrong pointing object 1674 0 (offset 0)\n",
      "Ignoring wrong pointing object 1677 0 (offset 0)\n",
      "Ignoring wrong pointing object 1725 0 (offset 0)\n",
      "Ignoring wrong pointing object 1735 0 (offset 0)\n",
      "Ignoring wrong pointing object 1753 0 (offset 0)\n",
      "Ignoring wrong pointing object 1755 0 (offset 0)\n",
      "Ignoring wrong pointing object 1793 0 (offset 0)\n",
      "Ignoring wrong pointing object 1795 0 (offset 0)\n",
      "Ignoring wrong pointing object 1952 0 (offset 0)\n",
      "Ignoring wrong pointing object 1969 0 (offset 0)\n",
      "Ignoring wrong pointing object 1978 0 (offset 0)\n",
      "Ignoring wrong pointing object 1990 0 (offset 0)\n",
      "Ignoring wrong pointing object 2059 0 (offset 0)\n",
      "Ignoring wrong pointing object 2068 0 (offset 0)\n",
      "Ignoring wrong pointing object 2076 0 (offset 0)\n",
      "Ignoring wrong pointing object 2079 0 (offset 0)\n",
      "Ignoring wrong pointing object 2081 0 (offset 0)\n",
      "Ignoring wrong pointing object 2083 0 (offset 0)\n",
      "Ignoring wrong pointing object 2085 0 (offset 0)\n",
      "Ignoring wrong pointing object 2087 0 (offset 0)\n",
      "Ignoring wrong pointing object 2089 0 (offset 0)\n",
      "Ignoring wrong pointing object 2091 0 (offset 0)\n",
      "Ignoring wrong pointing object 2093 0 (offset 0)\n",
      "Ignoring wrong pointing object 2095 0 (offset 0)\n",
      "Ignoring wrong pointing object 2097 0 (offset 0)\n",
      "Ignoring wrong pointing object 2099 0 (offset 0)\n",
      "Ignoring wrong pointing object 2101 0 (offset 0)\n",
      "Ignoring wrong pointing object 2103 0 (offset 0)\n",
      "Ignoring wrong pointing object 2105 0 (offset 0)\n",
      "Ignoring wrong pointing object 2107 0 (offset 0)\n",
      "Ignoring wrong pointing object 2280 0 (offset 0)\n",
      "Ignoring wrong pointing object 2298 0 (offset 0)\n",
      "Ignoring wrong pointing object 2300 0 (offset 0)\n",
      "Ignoring wrong pointing object 2302 0 (offset 0)\n",
      "Ignoring wrong pointing object 2306 0 (offset 0)\n",
      "Ignoring wrong pointing object 2310 0 (offset 0)\n",
      "Ignoring wrong pointing object 2329 0 (offset 0)\n",
      "Ignoring wrong pointing object 2331 0 (offset 0)\n",
      "Ignoring wrong pointing object 2333 0 (offset 0)\n",
      "Ignoring wrong pointing object 2337 0 (offset 0)\n",
      "Ignoring wrong pointing object 2369 0 (offset 0)\n",
      "Ignoring wrong pointing object 2371 0 (offset 0)\n",
      "Ignoring wrong pointing object 2373 0 (offset 0)\n",
      "Ignoring wrong pointing object 2377 0 (offset 0)\n",
      "Ignoring wrong pointing object 2427 0 (offset 0)\n",
      "Ignoring wrong pointing object 2436 0 (offset 0)\n",
      "Ignoring wrong pointing object 2443 0 (offset 0)\n",
      "Ignoring wrong pointing object 2456 0 (offset 0)\n",
      "Ignoring wrong pointing object 2459 0 (offset 0)\n",
      "Ignoring wrong pointing object 2472 0 (offset 0)\n",
      "Ignoring wrong pointing object 2474 0 (offset 0)\n",
      "Ignoring wrong pointing object 2488 0 (offset 0)\n",
      "Ignoring wrong pointing object 2490 0 (offset 0)\n",
      "Ignoring wrong pointing object 2493 0 (offset 0)\n",
      "Ignoring wrong pointing object 2545 0 (offset 0)\n",
      "Ignoring wrong pointing object 2559 0 (offset 0)\n",
      "Ignoring wrong pointing object 2569 0 (offset 0)\n",
      "Ignoring wrong pointing object 2594 0 (offset 0)\n",
      "Ignoring wrong pointing object 2629 0 (offset 0)\n",
      "Ignoring wrong pointing object 2773 0 (offset 0)\n",
      "Ignoring wrong pointing object 2886 0 (offset 0)\n",
      "Ignoring wrong pointing object 2921 0 (offset 0)\n",
      "Ignoring wrong pointing object 2949 0 (offset 0)\n",
      "Ignoring wrong pointing object 2968 0 (offset 0)\n",
      "Ignoring wrong pointing object 2974 0 (offset 0)\n",
      "Ignoring wrong pointing object 2996 0 (offset 0)\n",
      "Ignoring wrong pointing object 3012 0 (offset 0)\n",
      "Ignoring wrong pointing object 3128 0 (offset 0)\n",
      "Ignoring wrong pointing object 3159 0 (offset 0)\n",
      "Ignoring wrong pointing object 3171 0 (offset 0)\n",
      "Ignoring wrong pointing object 3189 0 (offset 0)\n",
      "Ignoring wrong pointing object 3254 0 (offset 0)\n",
      "Ignoring wrong pointing object 3257 0 (offset 0)\n",
      "Ignoring wrong pointing object 3260 0 (offset 0)\n",
      "Ignoring wrong pointing object 3263 0 (offset 0)\n",
      "Ignoring wrong pointing object 3329 0 (offset 0)\n",
      "Ignoring wrong pointing object 3331 0 (offset 0)\n",
      "Ignoring wrong pointing object 3336 0 (offset 0)\n",
      "Ignoring wrong pointing object 3338 0 (offset 0)\n",
      "Ignoring wrong pointing object 3399 0 (offset 0)\n",
      "Ignoring wrong pointing object 3411 0 (offset 0)\n",
      "Ignoring wrong pointing object 3434 0 (offset 0)\n",
      "Ignoring wrong pointing object 3464 0 (offset 0)\n",
      "Ignoring wrong pointing object 3474 0 (offset 0)\n",
      "Ignoring wrong pointing object 3485 0 (offset 0)\n",
      "Ignoring wrong pointing object 3516 0 (offset 0)\n",
      "Ignoring wrong pointing object 3528 0 (offset 0)\n",
      "Ignoring wrong pointing object 3577 0 (offset 0)\n",
      "Ignoring wrong pointing object 3593 0 (offset 0)\n",
      "Ignoring wrong pointing object 3603 0 (offset 0)\n",
      "Ignoring wrong pointing object 3624 0 (offset 0)\n",
      "Ignoring wrong pointing object 3639 0 (offset 0)\n",
      "Ignoring wrong pointing object 3644 0 (offset 0)\n",
      "Ignoring wrong pointing object 3735 0 (offset 0)\n",
      "Ignoring wrong pointing object 3885 0 (offset 0)\n",
      "Ignoring wrong pointing object 3889 0 (offset 0)\n",
      "Ignoring wrong pointing object 3911 0 (offset 0)\n",
      "Ignoring wrong pointing object 3934 0 (offset 0)\n",
      "Ignoring wrong pointing object 3969 0 (offset 0)\n",
      "Ignoring wrong pointing object 3979 0 (offset 0)\n",
      "Ignoring wrong pointing object 4033 0 (offset 0)\n",
      "Ignoring wrong pointing object 4036 0 (offset 0)\n",
      "Ignoring wrong pointing object 4038 0 (offset 0)\n",
      "Ignoring wrong pointing object 4102 0 (offset 0)\n",
      "Ignoring wrong pointing object 4311 0 (offset 0)\n",
      "Ignoring wrong pointing object 4313 0 (offset 0)\n",
      "Ignoring wrong pointing object 4315 0 (offset 0)\n",
      "Ignoring wrong pointing object 4356 0 (offset 0)\n",
      "Ignoring wrong pointing object 4434 0 (offset 0)\n",
      "Ignoring wrong pointing object 4436 0 (offset 0)\n",
      "Ignoring wrong pointing object 4439 0 (offset 0)\n",
      "Ignoring wrong pointing object 4443 0 (offset 0)\n",
      "Ignoring wrong pointing object 4446 0 (offset 0)\n",
      "Ignoring wrong pointing object 4449 0 (offset 0)\n",
      "Ignoring wrong pointing object 4452 0 (offset 0)\n",
      "Ignoring wrong pointing object 4455 0 (offset 0)\n",
      "Ignoring wrong pointing object 4612 0 (offset 0)\n",
      "Ignoring wrong pointing object 4631 0 (offset 0)\n",
      "Ignoring wrong pointing object 4674 0 (offset 0)\n",
      "Ignoring wrong pointing object 4720 0 (offset 0)\n",
      "Ignoring wrong pointing object 4723 0 (offset 0)\n",
      "Ignoring wrong pointing object 4731 0 (offset 0)\n",
      "Ignoring wrong pointing object 4734 0 (offset 0)\n",
      "Ignoring wrong pointing object 4803 0 (offset 0)\n",
      "Ignoring wrong pointing object 4826 0 (offset 0)\n",
      "Ignoring wrong pointing object 4852 0 (offset 0)\n",
      "Ignoring wrong pointing object 4946 0 (offset 0)\n",
      "Ignoring wrong pointing object 4969 0 (offset 0)\n",
      "Ignoring wrong pointing object 5060 0 (offset 0)\n",
      "Ignoring wrong pointing object 5106 0 (offset 0)\n",
      "Ignoring wrong pointing object 5108 0 (offset 0)\n",
      "Ignoring wrong pointing object 5144 0 (offset 0)\n",
      "Ignoring wrong pointing object 5168 0 (offset 0)\n",
      "Ignoring wrong pointing object 5177 0 (offset 0)\n",
      "Ignoring wrong pointing object 5180 0 (offset 0)\n",
      "Ignoring wrong pointing object 5213 0 (offset 0)\n",
      "Ignoring wrong pointing object 5237 0 (offset 0)\n",
      "Ignoring wrong pointing object 5252 0 (offset 0)\n",
      "Ignoring wrong pointing object 5270 0 (offset 0)\n",
      "Ignoring wrong pointing object 5334 0 (offset 0)\n",
      "Ignoring wrong pointing object 5338 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents_with_metadata_included(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required_exts = ['.pdf', '.tex']\n",
    "#reader = SimpleDirectoryReader(input_dir = \"../data\", required_exts = required_exts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Loaded {len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what one chunk looks like\n",
    "#print(f\"Chunk length: {len(docs[0].text)} characters\")\n",
    "#print(f\"Preview: {docs[0].text[:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceSplitter(chunk_size = 512, chunk_overlap= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will change the default embedding model from the OpenAI one to the sentence transformer model from HuggingFace as it is open-source and free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1065.12it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-V2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(model_name = 'sentence-transformers/all-MiniLM-L6-V2')\n",
    "Settings.node_parser = splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path = './chroma')\n",
    "chroma_collection = chroma_client.create_collection('ml_textbook_col') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection= chroma_collection,)\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, storage_context = storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 text chunks after repacking\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(response_mode = 'tree_summarize', verbose = True,  similarity_top_k = 10)\n",
    "\n",
    "response = query_engine.query(\"Summarize the ST443 Lecture 5 slides on regularisation. What are the main topics covered?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer : The ST443 Lecture 5 slides on regularization cover the following main topics:\n",
      "- Explanation of regularisation/penalisation\n",
      "- Best subset selection and stepwise selection\n",
      "- Model selection criteria\n",
      "- Ridge regression and shrinkage\n",
      "- Lasso regression and the sparsity-inducing ℓ1 penalty\n",
      "- Two general approaches: regularisation and dimension reduction\n",
      "\n",
      "Sources: \n",
      "\n",
      "1. Score: 0.423\n",
      "   File: ST443_Lecture_5.pdf\n",
      "   Text: Key learning points\n",
      "▶ What is regularisation/penalisation?\n",
      "▶ Best subset selection and stepwise selection\n",
      "▶ Model selection criteria\n",
      "▶ Ridge regression and shrinkage\n",
      "▶ Lasso regression and the sparsity-inducing ℓ1 penalty\n",
      "Milan Vojnović 2/36...\n",
      "\n",
      "2. Score: 0.361\n",
      "   File: ST443_Lecture_5.pdf\n",
      "   Text: Flexibility vs intepretability\n",
      "Milan Vojnović 6/36...\n",
      "\n",
      "3. Score: 0.358\n",
      "   File: ST443_Lecture_6.pdf\n",
      "   Text: Milan Vojnović 24/41...\n",
      "\n",
      "4. Score: 0.356\n",
      "   File: ST443_Lecture_5.pdf\n",
      "   Text: Two general approaches\n",
      "▶ Regularisation. Instead of just minimising the residual sum of squares, we\n",
      "add in an additional criteria in training that encourages low complexity\n",
      "models.\n",
      "▶ Dimension reduction. We first find a small set of directions that best\n",
      "summarise the variability in our data and perform subsequent analysis on\n",
      "synthetic variables created using these directions.\n",
      "– More on this in Lecture 9.\n",
      "Milan Vojnović 7/36...\n",
      "\n",
      "5. Score: 0.356\n",
      "   File: ISLRv2_corrected_June_2023.pdf\n",
      "   Text: We can also use different values of\n",
      "λfor the groups of weights from different layers; in this case W1andW2\n",
      "were penalized, while the relatively few weightsBof the output layer were\n",
      "not penalized at all. Lasso regularization is also popular as an additional\n",
      "form of regularization, or as an alternative to ridge.\n",
      "Figure10.18shows some metrics that evolve during the training of the\n",
      "network on theMNISTdata. It turns out that SGD naturally enforces its\n",
      "own form of approximately quadratic regularization.22Here the minibatch\n",
      "22This and other properties of SGD for deep learning are the subject of much research\n",
      "in the machine learning literature at the time of writing....\n",
      "\n",
      "6. Score: 0.355\n",
      "   File: elements_of_statistical_learning.pdf\n",
      "   Text: 166 5. Basis Expansions and Regularization\n",
      "125\n",
      "130\n",
      "135\n",
      "140\n",
      "145\n",
      "150\n",
      "155\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "20 30 40 50 60\n",
      "Age\n",
      "Obesity\n",
      "Systolic Blood Pressure\n",
      "120\n",
      "125\n",
      "130\n",
      "135\n",
      "140\n",
      "145\n",
      "150\n",
      "155\n",
      "160\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "\n",
      "7. Score: 0.351\n",
      "   File: mml-book.pdf\n",
      "   Text: 8.3 Parameter Estimation 265\n",
      "8.2.5 Further Reading\n",
      "Due to the fact that the original development of empirical risk minimiza-\n",
      "tion (Vapnik, 1998) was couched in heavily theoretical language, many\n",
      "of the subsequent developments have been theoretical. The area of study\n",
      "is called statistical learning theory (Vapnik, 1999; Evgeniou et al., 2000; statistical learning\n",
      "theoryHastie et al., 2001; von Luxburg and Sch¨olkopf, 2011). A recent machine\n",
      "learning textbook that builds on the theoretical foundations and develops\n",
      "efficient learning algorithms is Shalev-Shwartz and Ben-David (2014).\n",
      "The concept of regularization has its roots in the solution of ill-posed in-\n",
      "verse problems (Neumaier, 1998). The approach presented here is called\n",
      "Tikhonov regularization, and there is a closely related constrained version Tikhonov\n",
      "regularizationcalled Ivanov regularization. Tikhonov regularization has deep relation-\n",
      "ships to the bias-variance trade-off and feature selection (B ¨uhlmann and\n",
      "Van De Geer, 2011). An alternative to cross-validation is bootstrap and\n",
      "jackknife (Efron and Tibshirani, 1993; Davidson and Hinkley, 1997; Hall,\n",
      "1992).\n",
      "Thinking about empirical risk minimization (Section 8.2) as “probabil-\n",
      "ity free” is incorrect. There is an underlying unknown probability distri-\n",
      "bution p(x, y) that governs the data generation. However, the approach\n",
      "of empirical risk minimization is agnostic to that choice of distribution.\n",
      "This is in contrast to standard statistical approaches that explicitly re-\n",
      "quire the knowledge of p(x, y). Furthermore, since the distribution is a\n",
      "joint distribution on both examples x and labels y, the labels can be non-\n",
      "deterministic. In contrast to standard statistics we do not need to specify\n",
      "the noise distribution for the labels y.\n",
      "8.3 Parameter Estimation\n",
      "In Section 8.2, we did not explicitly model our problem using probability\n",
      "distributions....\n",
      "\n",
      "8. Score: 0.350\n",
      "   File: ST443_Lecture_1.pdf\n",
      "   Text: A fundamental picture\n",
      "We must keep this picture in mind when choosing a learning method.\n",
      "More flexible/complicated one is not always better!\n",
      "Milan Vojnović 33/33...\n",
      "\n",
      "9. Score: 0.346\n",
      "   File: ST443_Lecture_1.pdf\n",
      "   Text: Some relevant courses at LSE\n",
      "▶ ST444 Computational Data Science, 2024 AT.\n",
      "▶ ST449 Artificial Intelligence, 2024 AT.\n",
      "▶ ST451 Bayesian Machine Learning, 2025 WT.\n",
      "▶ ST455 Reinforcement Learning, 2024 WT.\n",
      "▶ ST456 Deep Learning, 2024 WT.\n",
      "▶ MY474 Applied Machine Learning for Social Science, 2024 AT.\n",
      "▶ MA429 Algorithmic Techniques for Data Mining, 2024 WT.\n",
      "Milan Vojnović 8/33...\n",
      "\n",
      "10. Score: 0.340\n",
      "   File: ST443_Lecture_3.pdf\n",
      "   Text: ▶ Always a good idea to use a smooth loss in training.\n",
      "Milan Vojnović 27/30...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Answer : {response.response}\")\n",
    "print(\"\\nSources: \")\n",
    "for i, node in enumerate(response.source_nodes, 1):\n",
    "    print(f\"\\n{i}. Score: {node.score:.3f}\")\n",
    "    print(f\"   File: {node.metadata.get('file_name', 'Unknown')}\")\n",
    "    print(f\"   Text: {node.text}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
